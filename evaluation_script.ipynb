{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This codes takes CIM Program data, CIM Assesssments Data, and Admissions data and returns effectiveness measure for TOC, COPD, and CHF Care Management Programs.\n",
    "\n",
    "Instructions for how to update.\n",
    "1. Run 3 SQL queries in zip folder - \"progs\", \"assessments\", and \"admits\", they are stored in github.com/tysonjens\n",
    "2. Run queries and save locally to your computer. Delimit query results with \"|\".\n",
    "3. Update \"read_csv\" commands (below) to corresopnd to your local paths\n",
    "4. Run the script and note outputs for the several analyses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse\n",
    "from pandas.tseries.offsets import Day\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import Imputer\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pyodbc\n",
    "# import statsmodels.formula.api as sm\n",
    "# import warnings; warnings.simplefilter('ignore')\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before importing and analyzing the data, we define several functions that help link and create features using the three data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function that finds the most recent discharge before a program begins\n",
    "def find_index_discharge_date(programs, admissions):\n",
    "    admissions = admissions.sort_values(by='discharge_date', ascending=False)\n",
    "    index_dates = np.empty(programs.shape[0])\n",
    "    index_dates[:] = np.nan\n",
    "    index_dates = list(index_dates)\n",
    "    for index, row in programs.iterrows():\n",
    "        admit_pat = admissions[admissions['EMPI']==row['EMPI']]\n",
    "        for index2, row2 in admit_pat.iterrows():\n",
    "            if row2['discharge_date'] < row['prog_create_date']:\n",
    "                index_dates[index] = row2['discharge_date']\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    return index_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function that finds the first assessment completed after discharge and records the date\n",
    "def find_first_assess(programs, assessments):\n",
    "    assessments = assessments.sort_values(by='ASES_DT', ascending=True)\n",
    "    first_assess_dates = np.empty(programs.shape[0])\n",
    "    first_assess_dates[:] = np.nan\n",
    "    first_assess_dates = list(first_assess_dates)\n",
    "    first_assess_name = np.empty(programs.shape[0])\n",
    "    first_assess_name[:] = np.nan\n",
    "    first_assess_name = list(first_assess_name)\n",
    "    for index, row in programs.iterrows():\n",
    "        assess_pat = assessments[assessments['EMPI']==row['EMPI']]\n",
    "        for index2, row2 in assess_pat.iterrows():\n",
    "            if row2['ASES_DT'] > row['index_date']:\n",
    "                first_assess_dates[index] = row2['ASES_DT']\n",
    "                first_assess_name[index] = row2['ASES_NM']\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    return first_assess_dates, first_assess_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function that finds a LACE score that occurred within 40 days (prior) to program start date\n",
    "def find_lace_prior_to_enroll(programs, lace, window_size=40):\n",
    "    lace = lace.sort_values(by='ASES_DT', ascending=False)\n",
    "    lace_scores = np.empty(programs.shape[0])\n",
    "    lace_scores[:] = np.nan\n",
    "    lace_scores = list(lace_scores)\n",
    "    for index, row in programs.iterrows():\n",
    "        lace_pat = lace[lace['EMPI']==row['EMPI']]\n",
    "        for index2, row2 in lace_pat.iterrows():\n",
    "            if (row2['ASES_DT'] < row['prog_create_date']) & (row2['ASES_DT'] > (row['prog_create_date']-timedelta(days=window_size))):\n",
    "                lace_scores[index] = row2['ASES_SCOR']\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    return lace_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function that finds the LACE dates that occurred within 40 days (prior) to program start date\n",
    "def find_lace_dt_prior_to_enroll(programs, lace, window_size=40):\n",
    "    lace = lace.sort_values(by='ASES_DT', ascending=False)\n",
    "    lace_dates = np.empty(programs.shape[0])\n",
    "    lace_dates[:] = np.nan\n",
    "    lace_dates = list(lace_dates)\n",
    "    for index, row in programs.iterrows():\n",
    "        lace_pat = lace[lace['EMPI']==row['EMPI']]\n",
    "        for index2, row2 in lace_pat.iterrows():\n",
    "            if (row2['ASES_DT'] < row['prog_create_date']) & (row2['ASES_DT'] > (row['prog_create_date']-timedelta(days=window_size))):\n",
    "                lace_dates[index] = row2['ASES_DT']\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    return lace_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that counts assessments that occur during a program.\n",
    "def find_assessments_during_program(programs, assess):\n",
    "    assess_cnt = np.zeros(programs.shape[0])\n",
    "    assess_cnt = list(assess_cnt)\n",
    "    for index, row in programs.iterrows():\n",
    "        assess_pat = assess[(assess['EMPI']==row['EMPI']) &\n",
    "                             (assess['ASES_DT'] > (row['prog_create_date']-timedelta(days=1))) &\n",
    "                             (assess['ASES_DT'] < (row['prog_end_date']+timedelta(days=1)))]\n",
    "        assess_cnt[index] = assess_pat.shape[0]\n",
    "    return assess_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that counts assessments in the 30-day window following a discharge (starts at \"index date\")\n",
    "def find_assessments_during_TOC(programs, assess):\n",
    "    assess_cnt_toc = np.zeros(programs.shape[0])\n",
    "    assess_cnt_toc = list(assess_cnt_toc)\n",
    "    for index, row in programs.iterrows():\n",
    "        assess_pat = assess[(assess['EMPI']==row['EMPI']) &\n",
    "                             (assess['ASES_DT'] > (row['index_date'])) &\n",
    "                             (assess['ASES_DT'] < (row['index_date']+timedelta(days=31)))]\n",
    "        assess_cnt_toc[index] = assess_pat.shape[0]\n",
    "    return assess_cnt_toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that counts assessments during the first 90 days of a program. Used in the this code for DM programs.\n",
    "def find_assessments_during_program_dm(programs, assess):\n",
    "    assess_cnt = np.zeros(programs.shape[0])\n",
    "    assess_cnt = list(assess_cnt)\n",
    "    for index, row in programs.iterrows():\n",
    "        assess_pat = assess[(assess['EMPI']==row['EMPI']) &\n",
    "                             (assess['ASES_DT'] > (row['prog_create_date']-timedelta(days=1))) &\n",
    "                             (assess['ASES_DT'] < (row['prog_create_date']+timedelta(days=91)))]\n",
    "        assess_cnt[index] = assess_pat.shape[0]\n",
    "    return assess_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convenience function that converts a list of counts into a binary \"flag\"\n",
    "def list_of_counts_to_flag(ases):\n",
    "    ases_yn = []\n",
    "    for num in ases:\n",
    "        if num>0:\n",
    "            ases_yn.append(1)\n",
    "        else:\n",
    "            ases_yn.append(0)\n",
    "    return ases_yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that counts the number of admits and length of stay in a window AFTER a program begins. For disease management\n",
    "def get_adm_after(programs, admissions, window_size=90):\n",
    "    admits_in_window = list(np.zeros(programs.shape[0]))\n",
    "    los_in_window = list(np.zeros(programs.shape[0]))\n",
    "    for index, row in programs.iterrows():\n",
    "        admit_pat = admissions[admissions['EMPI']==row['EMPI']]\n",
    "        count = 0\n",
    "        los = 0\n",
    "        for index2, row2 in admit_pat.iterrows():\n",
    "            if (row2['admit_date'] < (row['prog_create_date']+timedelta(days=window_size))) & (row2['admit_date'] > row['prog_create_date']):\n",
    "                count+=1\n",
    "                los += row2['length_of_stay']\n",
    "        admits_in_window[index] = count\n",
    "        los_in_window[index] = los\n",
    "    return admits_in_window, los_in_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that counts the number of admits and length of stay in a window BEFORE a program begins. For disease management.\n",
    "def get_adm_before(programs, admissions, window_size=90):\n",
    "    admits_in_window = list(np.zeros(programs.shape[0]))\n",
    "    los_in_window = list(np.zeros(programs.shape[0]))\n",
    "    for index, row in programs.iterrows():\n",
    "        admit_pat = admissions[admissions['EMPI']==row['EMPI']]\n",
    "        count = 0\n",
    "        los = 0\n",
    "        for index2, row2 in admit_pat.iterrows():\n",
    "            if (row2['admit_date'] > (row['prog_create_date']-timedelta(days=window_size))) & (row2['admit_date'] > (row['prog_create_date']-timedelta(days=10))):\n",
    "                count+=1\n",
    "                los += row2['length_of_stay']\n",
    "        admits_in_window[index] = count\n",
    "        los_in_window[index] = los\n",
    "    return admits_in_window, los_in_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that counts the number of admits in a window AFTER the index readmission. For TOC.\n",
    "def get_adm_after_index_discharge(programs, admissions, window_size=30):\n",
    "    admits_in_window = list(np.zeros(programs.shape[0]))\n",
    "    for index, row in programs.iterrows():\n",
    "        admit_pat = admissions[admissions['EMPI']==row['EMPI']]\n",
    "        count = 0\n",
    "        for index2, row2 in admit_pat.iterrows():\n",
    "            if (row2['admit_date'] < (row['index_date']+timedelta(days=window_size))) & (row2['admit_date'] > row['index_date']):\n",
    "                count+=1\n",
    "        admits_in_window[index] = count\n",
    "    return admits_in_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convenience function that converts a column of integer counts into a binary \"flag\"\n",
    "def adms_to_one_zero(progs, field):\n",
    "    adm_yn = []\n",
    "    for index, row in progs.iterrows():\n",
    "        if row[field]>0:\n",
    "            adm_yn.append(1)\n",
    "        else:\n",
    "            adm_yn.append(0)\n",
    "    return adm_yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plots \"Receiver Operating Characteristic\" Curve to evaluate Classification Model Performance.  \n",
    "## Takes \"TPR\" or true positive rates, and \"FPR\" for false positive rates for various thresholds and returns plot of curve\n",
    "def plotroc(TPR, FPR):\n",
    "    roc_auc = auc(TPR, FPR)\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(TPR, FPR, color='darkorange',\n",
    "             lw=lw, label=\"ROC curve area = {0:0.4f}\".format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that uses \"bootstraping\" to find the distribution of likely values for model coefficients.\n",
    "def bootstrap_ci_coefficients(X_train, y_train, num_bootstraps, class_weight={0: 1, 1: 1}):\n",
    "    bootstrap_estimates = []\n",
    "    for i in np.arange(num_bootstraps):\n",
    "        sample_index = np.random.choice(range(0, len(y_train)), len(y_train))\n",
    "        X_samples = X_train[sample_index]\n",
    "        y_samples = y_train[sample_index]\n",
    "        lm = linear_model.LogisticRegression(class_weight=class_weight, penalty='l1', C=100000000, solver='liblinear')\n",
    "        lm.fit(X_samples, y_samples)\n",
    "        bootstrap_estimates.append(lm.coef_[0])\n",
    "    bootstrap_estimates = np.asarray(bootstrap_estimates)\n",
    "    return bootstrap_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For COPD, find wehther or not there was a 90 day admission\n",
    "def tag_copd_admissions(dm_progs, rel_admits):\n",
    "    dm_admit_yn = list(np.zeros(rel_admits.shape[0]))\n",
    "    dm_optin_yn = np.empty(rel_admits.shape[0])\n",
    "    dm_optin_yn[:] = np.nan\n",
    "    dm_optin_yn = list(dm_optin_yn)\n",
    "    dm_week = np.empty(rel_admits.shape[0])\n",
    "    dm_week[:] = np.nan\n",
    "    dm_week = list(dm_optin_yn)\n",
    "    for index, row in dm_progs.iterrows():\n",
    "        for index2, row2 in rel_admits.iterrows():\n",
    "            if (row2['EMPI']==row['EMPI']) & (row2['admit_date'] > (row['prog_create_date']-timedelta(days=90))) & (row2['admit_date'] < (row['prog_create_date']+timedelta(days=90))):\n",
    "                dm_admit_yn[index2] = 1\n",
    "                dm_optin_yn[index2] = (row['copd_ases']>0)\n",
    "                dm_week[index2] = int(((row2['admit_date']-row['prog_create_date'])/timedelta(days=1))/7)\n",
    "    return dm_admit_yn, dm_optin_yn, dm_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For CHF, find wehther or not there was a 90 day admission\n",
    "def tag_chf_admissions(dm_progs, rel_admits):\n",
    "    dm_admit_yn = list(np.zeros(rel_admits.shape[0]))\n",
    "    dm_optin_yn = np.empty(rel_admits.shape[0])\n",
    "    dm_optin_yn[:] = np.nan\n",
    "    dm_optin_yn = list(dm_optin_yn)\n",
    "    dm_week = np.empty(rel_admits.shape[0])\n",
    "    dm_week[:] = np.nan\n",
    "    dm_week = list(dm_optin_yn)\n",
    "    for index, row in dm_progs.iterrows():\n",
    "        for index2, row2 in rel_admits.iterrows():\n",
    "            if (row2['EMPI']==row['EMPI']) & (row2['admit_date'] > (row['prog_create_date']-timedelta(days=90))) & (row2['admit_date'] < (row['prog_create_date']+timedelta(days=90))):\n",
    "                dm_admit_yn[index2] = 1\n",
    "                dm_optin_yn[index2] = (row['chf_ases']>0)\n",
    "                dm_week[index2] = int(((row2['admit_date']-row['prog_create_date'])/timedelta(days=1))/7)\n",
    "    return dm_admit_yn, dm_optin_yn, dm_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convinience function that converts integers less that 30 to \"1\", else \"0\" to identify patient who received med_rec\n",
    "def medrec_yn(medrec):\n",
    "    medrec_yn = []\n",
    "    medrec = list(medrec)\n",
    "    for i in medrec:\n",
    "        if i < 30:\n",
    "            medrec_yn.append(1)\n",
    "        else:\n",
    "            medrec_yn.append(0)\n",
    "    return medrec_yn\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('progs.sql', 'r') as myfile:\n",
    "#     progs_sql_str=myfile.read().replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnxn_progs = pyodbc.connect('DRIVER={SQL Server};SERVER=colo-dwrpt01;DATABASE=CIM_RPT')\n",
    "\n",
    "# progs = pd.read_sql(progs_sql_str, cnxn_progs)\n",
    "\n",
    "# cnxn_progs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## READ In Programs, Admissions, and Assessments data\n",
    "progs = pd.read_csv('../data/progs20190624.csv', sep='|', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remember to strip out SQL notifications from SQL results\n",
    "admits = pd.read_csv('../data/admissions20190624.csv', sep='|', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note that \"error_bad_lines=False\" instructs this code to ignore observations that don't have the expected number of columns\n",
    "assess = pd.read_csv('../data/assessments20190624.csv', sep='|', low_memory=False, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean progs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs = progs.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## python doesn't recognize dates as far as 2999, so replacing them with 2100\n",
    "mem_end_date = {'2999-12-31 00:00:00.000':'2100-12-31 00:00:00.000',\n",
    "               '2999-12-31 00:00:00':'2100-12-31 00:00:00.000'}\n",
    "progs['End_Date'] = progs['End_Date'].replace(mem_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#progs['End_Date'] = np.where(progs['End_Date'].year == 2999, progs['End_Date'].replace(year=2100), progs['End_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert dates to date time\n",
    "progs['prog_create_date'] = pd.to_datetime(progs['ASGN_TMS'])\n",
    "progs['date_of_birth'] = pd.to_datetime(progs['DOB'])\n",
    "progs['prog_end_date'] = pd.to_datetime(progs['END_TMS'])\n",
    "progs['Eff_Date'] = pd.to_datetime(progs['Eff_Date'])\n",
    "progs['End_Date'] = pd.to_datetime(progs['End_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## create opt-in and opt-out with stop reason\n",
    "# opt_in = {'Admit to Facility':1, 'Discharge to Custodial':1, 'Discharged to Hospice':1, \n",
    "#           'Discharged to PCP':1, 'Goals Met':1, 'Referred to other program':1, \n",
    "#           'Refused':0, 'Unable to Reach':0, 'Barriers to participation':0, 'Expired':np.nan, \n",
    "#          'Criteria not met':np.nan, 'Disenrolled from HP/Medical Group':np.nan, '6 months/1 year post transplant':np.nan,\n",
    "#        'Pharmacy - physician recommended':np.nan}\n",
    "# progs['is_optin'] = progs['PRGM_STOP_RSN'].replace(opt_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace date_of_birth with age\n",
    "progs['age'] = datetime.now() - progs['date_of_birth']\n",
    "progs['age'] = progs['age'] / timedelta(days=1) / 365\n",
    "progs['age'].fillna(float(progs['age'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replate \"M\"/\"F\" with 1/0\n",
    "new_sex = {'F':0, 'M':1, 'U':1, 'I':0}\n",
    "progs['is_male'] = progs['Sex'].replace(new_sex)\n",
    "progs['is_male'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop unneeded columns\n",
    "prog_cols_drop = ['PTNT_DK', 'DOB', 'Sex', 'ASGN_TMS', 'END_TMS', 'TNT_MKT_BK', 'date_of_birth', 'PRGM_STS', 'Patient_SK', 'CLNC_NM'\n",
    "                 ,'Race','ZipCode', 'Current_Member', 'Deceased_Flag', 'HP_NM', 'PRIM_PRGM_FLAG']\n",
    "progs = progs.drop(prog_cols_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs = progs.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changes to program and assessment policies continued through July 1, 2018. \n",
    "## Subset programs after that date to keep things clean\n",
    "progs = progs[(progs['prog_create_date']>'2018-07-01') & \n",
    "              (progs['prog_create_date']<(datetime.today()-timedelta(days=30)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Having subset dataframe, reset the index. This is so functions that use index work properly\n",
    "progs = progs.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ensure programs and assessment EMPI are the same data type so they can be compared\n",
    "progs['EMPI'] = progs['EMPI'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert object columns to categoricals so they can be converted to dummy variables later\n",
    "for col in ['RGON_NM', 'LOB_SUB_CGY', 'PRGM_NM', 'PRGM_STOP_RSN']:\n",
    "    progs[col] = progs[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Admits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A few observations have \"Nan\" EMPIs. Convert to \"999999999\" to ensure functions work and they are ignored\n",
    "admits['EMPI'].fillna(999999999, inplace=True)\n",
    "\n",
    "admits['EMPI'] = admits['EMPI'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert dates to date time\n",
    "admits['admit_date'] = pd.to_datetime(admits['ACT_ADM_DT'])\n",
    "admits['discharge_date'] = pd.to_datetime(admits['ACT_DISCH_DT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate length of stay using admit date and discharge date\n",
    "admits['length_of_stay'] = ((admits['discharge_date']-admits['admit_date']) / np.timedelta64(1, 'D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop unneeded columns\n",
    "admits_cols_drop = ['REFERRAL_KEY', 'PATIENT', 'ACT_ADM_DT', 'ACT_DISCH_DT',\n",
    "       'PriorAcuteDisch', 'PriorAcuteAdm', 'PriorSubDisch', 'PriorSubAdm',\n",
    "       'DISCHARGE_DISPOSITION']\n",
    "admits = admits.drop(admits_cols_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove assessments with weird filler date '2917-12-26 00:00:00.000'\n",
    "assess = assess[assess['ASES_DT']!='2917-12-26 00:00:00.000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note January 30, 2019 - we began using \"COMPLETION_DATE\" instead of \"ASES_DT\", but in the query we have aliased \n",
    "## \"COMPLETION DATE\" as \"ASES_DT\" for code\n",
    "assess['ASES_DT'] = pd.to_datetime(assess['ASES_DT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess['EMPI'] = assess['EMPI'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for all programs, find the most recent discharge date (prior to program create date)\n",
    "index_dates = find_index_discharge_date(progs, admits)\n",
    "progs['index_date'] = index_dates\n",
    "progs['index_date'] = pd.to_datetime(progs['index_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## subset all assessments to just LACE assessments - to be used below.\n",
    "LACE = assess[assess['ASES_NM']=='LACE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find lace scores that occurred recently (before program started) - 40 day window\n",
    "lace_scores = find_lace_prior_to_enroll(progs, LACE)\n",
    "progs['lace_score'] = lace_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find dates of most recent LACE score\n",
    "lace_dates = find_lace_dt_prior_to_enroll(progs, LACE, window_size=1000)\n",
    "progs['lace_date_prior_enroll'] = lace_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the number of days from the lace assessment to TOC program enrollment\n",
    "progs['lace_to_enroll_days'] = (progs['prog_create_date']-progs['lace_date_prior_enroll'])/ timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find TOC assessments that matter for TOC\n",
    "## 'MCG - Post-Hospitalization Follow-Up' was discontinued, but left in here to properly identify opt-in from historical data\n",
    "assess_toc = assess[(assess['ASES_NM']=='MCG - Post-Hospitalization Follow-Up') |\n",
    "                    (assess['ASES_NM']=='Post-Hospitalization Follow-up')\n",
    "                  |  (assess['ASES_NM']=='Pharm - Post-Hospitalization Follow-up')\n",
    "                    |  (assess['ASES_NM']=='Pharm ? Post-Hospitalization Follow-up')\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subset assessments to Med Rec assessments\n",
    "assess_medrec = assess[(assess['ASES_NM']=='CM Medication Reconciliation') |\n",
    "                       (assess['ASES_NM']=='Med Reconciliation')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the number of admits that occur within a 30-day window after program begins\n",
    "thirty_day_after_adm, thirty_day_after_bd  = get_adm_after(progs, admits, window_size=30)\n",
    "progs['adm_30_after'] = thirty_day_after_adm\n",
    "progs['los_30_after'] = thirty_day_after_bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the number of admits and length of stay that occur within 90 day window after program begins\n",
    "ninety_day_after_adm, ninety_day_after_bd = get_adm_after(progs, admits, window_size=90)\n",
    "progs['adm_90_after'] = ninety_day_after_adm\n",
    "progs['los_90_after'] = ninety_day_after_bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the number of admits and length of Stay that occur within 90 day window before program begins\n",
    "ninety_day_before_adm , ninety_day_before_bd = get_adm_before(progs, admits)\n",
    "progs['adm_90_before'] = ninety_day_before_adm\n",
    "progs['los_90_before'] = ninety_day_before_bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate days from index discharge date to program create date, second line converts \"datetime\" format to integer\n",
    "progs['time_to_enroll'] = progs['prog_create_date']-progs['index_date']\n",
    "progs['time_to_enroll'] = progs['time_to_enroll']/ timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate program duration\n",
    "progs['prog_duration'] = (progs['prog_end_date'].fillna(datetime.today()))-progs['prog_create_date']\n",
    "progs['prog_duration'] = progs['prog_duration']/ timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find dates and names of first TOC assessment during program\n",
    "toc_first_ases_dt, toc_first_ases_nm = find_first_assess(progs, assess_toc)\n",
    "\n",
    "progs['toc_first_ases_dt'] = toc_first_ases_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find dates and names of first med rec assessment during program\n",
    "medrec_first_ases_dt, medrec_first_ases_nm = find_first_assess(progs, assess_medrec)\n",
    "\n",
    "progs['medrec_first_ases_dt'] = medrec_first_ases_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converts column to \"datetime\"\n",
    "progs['toc_first_ases_dt'] = pd.to_datetime(progs['toc_first_ases_dt'])\n",
    "progs['medrec_first_ases_dt'] = pd.to_datetime(progs['medrec_first_ases_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate time between index discharge and first relevant assessment or med rec\n",
    "progs['index_to_first_ases'] = (progs['toc_first_ases_dt']-progs['index_date'])/timedelta(days=1)\n",
    "progs['index_to_medrec'] = (progs['medrec_first_ases_dt']-progs['index_date'])/timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create flag for whether med rec took place within 30 days after discharge\n",
    "medrec_yn = medrec_yn(progs['index_to_medrec'])\n",
    "progs['medrec_yn'] = medrec_yn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Gut check - distribution of time to enroll should follow a skinny exponential distribution\n",
    "## Most enrolls should happen in the first few days, then quickly tapers to long tail\n",
    "\n",
    "fighist = plt.figure(figsize=(12,6))\n",
    "ax1 = fighist.add_subplot(111)\n",
    "ax1.set_title('Histogram, time to enroll post discharge')\n",
    "ax1.hist(np.array(progs[progs['PRGM_NM']=='Transitions of Care - Post Discharge']['time_to_enroll'].dropna()), bins = 100, alpha = 0.4, density=1, label='TOC')\n",
    "#ax1.hist(np.array(progs[progs['PRGM_NM']=='DM - CLD']['time_to_enroll'].dropna()), bins = 40, alpha = 0.6, density=1, label='CLD')\n",
    "#ax1.hist(np.array(progs[progs['PRGM_NM']=='DM - HF']['time_to_enroll'].dropna()), bins = 40, alpha = 0.6, density=1, label='HF')\n",
    "ax1.set_ylabel('Percent of Patients')\n",
    "ax1.set_xlabel('days to enrollment')\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOC - Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs[(progs['PRGM_NM']=='Transitions of Care - Post Discharge')].drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subset programs list to only include active members and enrollments associated with a discharge.\n",
    "## Also removes patients without a lace score OR whose program was \"auto-closed\" as a data clean up measure.\n",
    "progs_toc_w_lace = progs[(progs['PRGM_NM']=='Transitions of Care - Post Discharge') &\n",
    "                  ((progs['prog_create_date']-timedelta(days=30))>progs['Eff_Date']) &\n",
    "                  ((progs['prog_create_date']-timedelta(days=30))<progs['End_Date']) &\n",
    "                  ((progs['time_to_enroll']<30)) &\n",
    "                  (progs['PRGM_STOP_RSN']!='Auto-Closed')  &\n",
    "                  (progs['lace_score'].isna()==False) &  \n",
    "                  (progs['prog_create_date']<(datetime.today()-timedelta(days=35)))\n",
    "                 ].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_toc_w_lace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify assessments that occured during TOC window that interfere with the opt-out effect.\n",
    "assess_that_muddy = assess[(assess['ASES_NM'] == 'Social Work Initial') |\n",
    "      ##(assess['ASES_NM'] == 'MCG - DMG - Preventative Assessment') |\n",
    "      ##(assess['ASES_NM'] == 'Social Work Outreach Encounter') |\n",
    "      (assess['ASES_NM'] == 'MCG - DMG - High-Risk Pregnancy - Assessment') | \n",
    "      (assess['ASES_NM'] == 'Social Work Note') |\n",
    "      (assess['ASES_NM'] == 'Transplant Notes') |\n",
    "      (assess['ASES_NM'] == 'MCG - DMG - Diabetes, Adult - Knowledge of Condition and Treatment Plan') |\n",
    "      (assess['ASES_NM'] == 'MCG - DMG - Complex Assessment') |\n",
    "      ##(assess['ASES_NM'] == 'IVR Survey') |\n",
    "      (assess['ASES_NM']=='MCG - Heart Failure - Knowledge of Condition and Treatment Plan') |\n",
    "      (assess['ASES_NM']=='MCG - DMG - Heart Failure - Knowledge of Condition and Treatment Plan') |\n",
    "      (assess['ASES_NM']=='MCG - Chronic Obstructive Pulmonary Disease - Knowledge of Condition and Treatment Plan') |\n",
    "      (assess['ASES_NM']=='MCG - DMG - Chronic Lung Disease (CLD)') |\n",
    "      (assess['ASES_NM'] == 'MCG - DMG - Heart Failure') |\n",
    "      (assess['ASES_NM'] == 'MCG - DMG - CLD')].drop_duplicates(subset='PTNT_ASES_DK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count the number of interfering assessments that occur during a TOC program\n",
    "assess_toc_cnt = find_assessments_during_TOC(progs_toc_w_lace, assess_that_muddy)\n",
    "progs_toc_w_lace['assess_dur_TOC_cnt'] = assess_toc_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create count and y/n columns for assessment that interfere\n",
    "cm_toc_ases = find_assessments_during_program(progs_toc_w_lace, assess_toc)\n",
    "cm_toc_ases_flag = list_of_counts_to_flag(cm_toc_ases)\n",
    "progs_toc_w_lace['cnt_toc_cm_touch'] = cm_toc_ases\n",
    "progs_toc_w_lace['toc_cm_touch_yn'] = cm_toc_ases_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subset to only include patients that had no interfering assessments during their 30-day TOC window\n",
    "toc_interfere_ind = adms_to_one_zero(progs_toc_w_lace, 'assess_dur_TOC_cnt')\n",
    "progs_toc_w_lace['toc_interfere_ind'] = toc_interfere_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean opt-ins and opt-outs using the 'toc_interfere_ind'\n",
    "\n",
    "progs_toc_w_lace = progs_toc_w_lace[progs_toc_w_lace['toc_interfere_ind']==0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Counts readmission in 30-day TOC window\n",
    "thirty_day_after_TOC = get_adm_after_index_discharge(progs_toc_w_lace, admits)\n",
    "progs_toc_w_lace['adm_30_after_TOC'] = thirty_day_after_TOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converts counts of admission to binary flag\n",
    "adm_yn = adms_to_one_zero(progs_toc_w_lace, 'adm_30_after_TOC')\n",
    "progs_toc_w_lace['is_30_TOC_adm'] = adm_yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop unneeded columns\n",
    "admits_cols_drop = ['level_0', 'index', 'Eff_Date', 'End_Date', 'ASGN_USR', 'lace_date_prior_enroll',\n",
    "       'adm_30_after', 'los_90_after', 'los_90_before', 'toc_first_ases_dt'\n",
    "                   ,'medrec_first_ases_dt']\n",
    "progs_toc_w_lace = progs_toc_w_lace.drop(admits_cols_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the filename you wish to save the file to\n",
    "toc_regression_filename = '../data/progs_toc_20190517.csv'\n",
    "\n",
    "# Use this function to search for any files which match your filename\n",
    "files_present = os.path.isfile(toc_regression_filename)\n",
    "\n",
    "# if no matching files, write to csv, if there are matching files, print statement\n",
    "if not files_present:\n",
    "    progs_toc_w_lace.to_csv(toc_regression_filename)\n",
    "else:\n",
    "    print('WARNING: This file already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create binary dummy columns for each value in categorical variables\n",
    "progs_toc_ent = pd.get_dummies(pd.Series(list(progs_toc_w_lace['ENT_TYPE'])))\n",
    "progs_toc_lob = pd.get_dummies(pd.Series(list(progs_toc_w_lace['LOB_SUB_CGY'])))\n",
    "progs_toc_rgn = pd.get_dummies(pd.Series(list(progs_toc_w_lace['RGON_NM'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merges dummy columns into dataframe\n",
    "progs_toc_w_lace = pd.concat([progs_toc_w_lace, progs_toc_lob, progs_toc_ent, progs_toc_rgn], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOC - Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_toc_w_lace[(progs_toc_w_lace['toc_cm_touch_yn']==0)]['los_30_after'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the distribution of length of stay for TOC patients\n",
    "\n",
    "fighist = plt.figure(figsize=(12,6))\n",
    "ax1 = fighist.add_subplot(111)\n",
    "ax1.set_title('Histogram, length of stay')\n",
    "ax1.hist(np.array(progs_toc_w_lace[(progs_toc_w_lace['toc_cm_touch_yn']==0)]['los_30_after'].dropna()), bins = 20, alpha = 0.4, density=1, label='TOC')\n",
    "#ax1.hist(np.array(progs[progs['PRGM_NM']=='DM - CLD']['time_to_enroll'].dropna()), bins = 40, alpha = 0.6, density=1, label='CLD')\n",
    "#ax1.hist(np.array(progs[progs['PRGM_NM']=='DM - HF']['time_to_enroll'].dropna()), bins = 40, alpha = 0.6, density=1, label='HF')\n",
    "ax1.set_ylabel('Percent of Patients')\n",
    "ax1.set_xlabel('length of stay, days')\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convenience code to explore correlation between one variable and all other variables\n",
    "progs_toc_w_lace.corr()['prog_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convenience code to pivot readmission flag and opt-in / opt-out flag\n",
    "progs_toc_w_lace.pivot_table(values='is_30_TOC_adm', columns='toc_cm_touch_yn', aggfunc=['mean', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOC - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In earlier versions classes were more imbalanced. We accounted for this by assigning more importance\n",
    "## to the minority class. In later version, we kept each class's importance = 1.\n",
    "class_weight={0: 1, 1: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selects explanatory variables for regression\n",
    "x_cols = ['toc_cm_touch_yn', 'time_to_enroll', 'lace_score', 'prog_duration', 'IPA', 'MEDI-CAL', 'COMMERCIAL', 'is_male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subsets columns to relevant columns \n",
    "X = np.array(progs_toc_w_lace[x_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Convenience Code to impute values for nulls in each column. \n",
    "# imput = Imputer(strategy='most_frequent')\n",
    "# X = imput.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creates array for \"Y\" - our target variable.\n",
    "y_ad_yn = np.array(progs_toc_w_lace['is_30_TOC_adm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code can split the dataset into training and test sets.\n",
    "## In practice, we assign the entire dataset to training because we haven't used the model to predict\n",
    "## This increases our n and helps find a signal for program effectiveness\n",
    "X_ad_train, X_ad_test, y_ad_yn_train, y_ad_yn_test = train_test_split(X, y_ad_yn, test_size=.1, random_state=65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creates a logistic regression instance. C=100000000 reduces regularization to 0.\n",
    "model_ad = linear_model.LogisticRegression(C=100000000, class_weight=class_weight, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'I' in X_ad_train[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fits model instance using our X and Y matricies\n",
    "model_ad.fit(X_ad_train, y_ad_yn_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOC - Explore Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Having fit the model, we can now extract coefficients for X variables.\n",
    "model_ad.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Having fit the model, we can now extract the y intercept\n",
    "model_ad.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bootstrap likely distributions of values that each coefficient takes\n",
    "ad_yn_bootstraps = bootstrap_ci_coefficients(X, y_ad_yn, 2000)\n",
    "ad_yn_bootstraps = pd.DataFrame(ad_yn_bootstraps, columns=x_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Plots distributions of likely values for each X variable\n",
    "fig, axes = plt.subplots(2,4, figsize=(16,8))\n",
    "col_names = x_cols\n",
    "\n",
    "for m, ax in zip(col_names, axes.flatten()):\n",
    "    ax.hist(ad_yn_bootstraps[m], bins=50)\n",
    "    ax.plot([0, 0], [0, 155], color='red', linestyle='-', linewidth=2)\n",
    "    ax.set_xlim(right=.5, left=-.5)\n",
    "    ax.set_title(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate Model Accuracy\n",
    "r2 = model_ad.score(X, y_ad_yn)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate prediction probabilities and evaluate \n",
    "## predictiveness of model with AUC.\n",
    "y_ad_yn_preds = model_ad.predict_proba(X_ad_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_TPR, ad_FPR, ad_thresholds = roc_curve(y_ad_yn_test, y_ad_yn_preds, pos_label=None, sample_weight=None, drop_intermediate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot AUC, which helps determine the predictive value of the model\n",
    "plotroc(ad_TPR, ad_FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate predictions and evaluate predictiveness of model with AUC.\n",
    "y_ad_yn_preds = model_ad.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ad_yn_preds_act = model_ad.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_readmission_rate_optins = progs_toc_w_lace[progs_toc_w_lace['toc_cm_touch_yn']==1]['is_30_TOC_adm'].mean()\n",
    "print(act_readmission_rate_optins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the actual readmission rate\n",
    "act_readmission_rate_pop = y_ad_yn.mean()\n",
    "print(act_readmission_rate_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a mirror image of our X matrix\n",
    "x1 = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set all opt-ins to opt-outs\n",
    "x1[:,0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find what the model predicts the readmission likelihoods would be for each patient\n",
    "y_ad_yn_preds_nooptins = model_ad.predict_proba(x1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FIND the expected readmission rate of the population\n",
    "exp_readmission_rate_pop = y_ad_yn_preds_nooptins.mean()\n",
    "print(exp_readmission_rate_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_toc_w_lace['is_30_TOC_adm_pred'] = y_ad_yn_preds_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_effect = (exp_readmission_rate_pop - act_readmission_rate_pop)/exp_readmission_rate_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optin_effect = (progs_toc_w_lace.shape[0])*pop_effect/(progs_toc_w_lace[(progs_toc_w_lace['toc_cm_touch_yn']==1)].shape[0])\n",
    "print(optin_effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use optin effect and actual optin readmission rate to infer optin readmission rate if there had be no optins\n",
    "exp_readmission_rate_optins = act_readmission_rate_optins/(1-optin_effect)\n",
    "print(exp_readmission_rate_optins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['toc_cm_touch_yn', 'time_to_enroll', 'lace_score', 'prog_duration', 'IPA', 'MEDI-CAL', 'COMMERCIAL', 'is_male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Theoretical effect of opting in on odds\n",
    "exp_effect_odds = 1-np.exp(model_ad.coef_[0][0])\n",
    "print(exp_effect_odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_int_logodds = np.percentile(np.array(ad_yn_bootstraps['toc_cm_touch_yn']), [2.5,50,97.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Effect Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_int_odds = 1-np.exp(np.percentile(np.array(ad_yn_bootstraps['toc_cm_touch_yn']), [2.5,50,97.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ad.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_exp = model_ad.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experimental effect of opting in on odds\n",
    "# Average Patient: Time to enroll is 6, lace score 10, prog duration 17, Medicare, male\n",
    "odds_0 = np.exp(np.sum(np.array([0, 6, 10, 17, 1, 0, 0, 1])* coefs_exp.reshape(1,-1))+model_ad.intercept_[0])\n",
    "odds_exp_1 = np.exp(np.sum(np.array([1, 6, 10, 17, 1, 0, 0, 1])* coefs_exp.reshape(1,-1))+model_ad.intercept_[0])\n",
    "print(odds_0)\n",
    "print(odds_exp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert odds to probability for the opt-out case.  This is used for expected, high, and low calculations\n",
    "proba_0 = odds_0/(1+odds_0)\n",
    "print(proba_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert odds to probability for the expected case.\n",
    "exp_proba_1 = odds_exp_1/(1+odds_exp_1)\n",
    "print(exp_proba_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the reduction in readmission probability for the expected case\n",
    "exp_effect_proba = (proba_0 - exp_proba_1)/proba_0\n",
    "print('The most likely effect is a {:.1%} reduction in readmission likelihood.'.format(exp_effect_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the absolute risk reduections for the expected case\n",
    "exp_ARR = exp_readmission_rate_optins*exp_effect_proba\n",
    "print(exp_ARR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The program is estimated to reduce admissions by {:.1f} for every 1,000 \"Opt-ins\".'.format(exp_ARR*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High Effect Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_high = model_ad.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_high[0] = conf_int_logodds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experimental effect of opting in on odds\n",
    "# Average Patient: Time to enroll is 6, lace score 10, prog duration 17, Medicare, male\n",
    "high_odds_1 = np.exp(np.sum(np.array([1, 6, 10, 17, 1, 0, 0, 1])* coefs_high.reshape(1,-1))+model_ad.intercept_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_proba_1 = high_odds_1/(1+high_odds_1)\n",
    "print(high_proba_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_effect_proba = (proba_0 - high_proba_1)/proba_0\n",
    "print('The highest likely effect is a {:.1%} reduction in readmission likelihood.'.format(high_effect_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_ARR = exp_readmission_rate_optins*high_effect_proba\n",
    "print(high_ARR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low Effect Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_low = model_ad.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_low[0] = conf_int_logodds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experimental effect of opting in on odds\n",
    "# Average Patient: Time to enroll is 6, lace score 10, prog duration 17, Medicare, male\n",
    "low_odds_1 = np.exp(np.sum(np.array([1, 6, 10, 17, 1, 0, 0, 1])* coefs_low.reshape(1,-1))+model_ad.intercept_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_proba_1 = low_odds_1/(1+low_odds_1)\n",
    "print(low_proba_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_effect_proba = (proba_0 - low_proba_1)/proba_0\n",
    "print('The lowest likely effect is a {:.1%} reduction in readmission likelihood.'.format(low_effect_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_ARR = exp_readmission_rate_optins*low_effect_proba\n",
    "print(low_ARR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The 95% confidence interval ranges between {:.1%} and {:.1%}.'.format(high_effect_proba, low_effect_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_low = coefs_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number needed to treat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The estimated NNT is {:.0f}, but could be as high as {:.0f} or as low as {:.0f}.'.format(\n",
    "    1/exp_ARR, 1/low_ARR, 1/high_ARR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHF - Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an \"image\" of all programs data set, specifically for CHF.\n",
    "progs_chf = progs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_chf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subset all programs to relevant CHF programs.\n",
    "progs_chf = progs_chf[(progs_chf['PRGM_NM']=='DM - HF') &\n",
    "                    ((progs_chf['prog_create_date']-timedelta(days=90))>progs_chf['Eff_Date']) &\n",
    "                    ((progs_chf['prog_create_date']-timedelta(days=90))<progs_chf['End_Date']) &\n",
    "                      (progs_chf['PRGM_STOP_RSN']!='Auto-Closed')  &\n",
    "                      (progs_chf['prog_create_date']<(datetime.today()-timedelta(days=90)))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_chf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify Assessments that occured during CHF window that interfere with the opt-out population.\n",
    "assess_that_muddy_chf = assess[(assess['ASES_NM'] == 'Social Work Initial') |\n",
    "      (assess['ASES_NM'] == 'Social Work Note') |\n",
    "      (assess['ASES_NM'] == 'Transplant Notes') |\n",
    "      (assess['ASES_NM'] == 'MCG - DMG - Diabetes, Adult - Knowledge of Condition and Treatment Plan') |\n",
    "      (assess['ASES_NM'] == 'MCG - DMG - Complex Assessment') |\n",
    "      ##(assess['ASES_NM'] == 'MCG - DMG - Preventative Assessment') |\n",
    "      ##(assess['ASES_NM'] == 'Social Work Outreach Encounter') |\n",
    "      (assess['ASES_NM'] == 'MCG - DMG - High-Risk Pregnancy - Assessment') | \n",
    "      (assess['ASES_NM'] == 'MCG - Heart Failure - Knowledge of Condition and Treatment Plan') | \n",
    "      (assess['ASES_NM'] == 'MCG - DMG - Heart Failure - Knowledge of Condition and Treatment Plan') | \n",
    "      ##(assess['ASES_NM'] == 'IVR Survey') |\n",
    "      (assess['ASES_NM'] == 'MCG - DMG - CLD') |\n",
    "      (assess['ASES_NM']=='MCG - Post-Hospitalization Follow-Up') | \n",
    "      (assess['ASES_NM']=='Post-Hospitalization Follow-up') |\n",
    "      ##(assess['ASES_NM']=='TOC Post Discharge Outreach') | removed on 4/2 per discussion with Sameer/Adam\n",
    "      (assess['ASES_NM']=='CM Medication Reconciliation') |\n",
    "      (assess['ASES_NM']=='Med Reconciliation')].drop_duplicates(subset='PTNT_ASES_DK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create assessments table for CHF\n",
    "assess_chf_mhfk = assess[assess['ASES_NM']=='MCG - Heart Failure - Knowledge of Condition and Treatment Plan']\n",
    "assess_chf_mdhf = assess[assess['ASES_NM']=='MCG - DMG - Heart Failure']\n",
    "assess_chf_mdhfk = assess[assess['ASES_NM']=='MCG - DMG - Heart Failure - Knowledge of Condition and Treatment Plan']\n",
    "frames = [assess_chf_mhfk, assess_chf_mdhf, assess_chf_mdhfk]\n",
    "assess_chf = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count interfering assessments during program\n",
    "assess_chf_cnt = find_assessments_during_program_dm(progs_chf, assess_that_muddy_chf)\n",
    "progs_chf['assess_dur_chf_cnt'] = assess_chf_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cnt chf related assessments during programs\n",
    "cnt_chf_90 = find_assessments_during_program_dm(progs_chf, assess_chf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converts counts to flag indicating whether a patient opted in or out of the CHF program\n",
    "progs_chf['chf_ases'] = cnt_chf_90\n",
    "cm_chf_ases_yn = list_of_counts_to_flag(cnt_chf_90)\n",
    "progs_chf['chf_ases_yn'] = cm_chf_ases_yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creates flag if program has an interfering assessment, subsets programs to those where flag==0\n",
    "chf_interfere_ind = adms_to_one_zero(progs_chf, 'assess_dur_chf_cnt')\n",
    "progs_chf['chf_interfere_ind'] = chf_interfere_ind\n",
    "\n",
    "progs_chf = progs_chf[((progs_chf['chf_interfere_ind']==0) & (progs_chf['chf_ases_yn']==0)) |\n",
    "                     (progs_chf['chf_ases_yn']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_chf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_chf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify the date and name of first CHF assessment within a CHF program\n",
    "chf_first_ases_dt, chf_first_ases_nm = find_first_assess(progs_chf, assess_chf)\n",
    "\n",
    "progs_chf['chf_first_ases_dt'] = chf_first_ases_dt\n",
    "progs_chf['chf_first_ases_nm'] = chf_first_ases_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_chf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the filename you wish to save the file to\n",
    "progs_chf_filename = '../data/progs_chf_20190331.csv'\n",
    "\n",
    "# Use this function to search for any files which match your filename\n",
    "files_present = os.path.isfile(progs_chf_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if no matching files, write to csv, if there are matching files, print statement\n",
    "if not files_present:\n",
    "    progs_chf.to_csv(progs_chf_filename)\n",
    "else:\n",
    "    print('WARNING: This file already exists!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHF - Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_chf.pivot_table(values=['adm_90_after', 'adm_90_before'], index='chf_ases_yn', aggfunc=['mean', 'count', 'sum'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop Dataset for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_chf_reg = progs_chf.drop(columns = ['index', 'RGON_NM', 'LOB_SUB_CGY', 'ENT_TYPE', 'Eff_Date',\n",
    "       'End_Date', 'PRGM_NM', 'PRGM_STOP_RSN', 'ASGN_USR', 'prog_create_date',\n",
    "       'prog_end_date', 'age', 'is_male', 'index_date', 'lace_score',\n",
    "       'lace_date_prior_enroll', 'lace_to_enroll_days', 'adm_30_after',\n",
    "       'los_30_after', 'los_90_after',\n",
    "       'los_90_before', 'time_to_enroll', 'prog_duration', 'toc_first_ases_dt',\n",
    "       'medrec_first_ases_dt', 'index_to_first_ases', 'index_to_medrec',\n",
    "       'medrec_yn', 'assess_dur_chf_cnt', 'chf_ases',\n",
    "       'chf_interfere_ind', 'chf_first_ases_dt', 'chf_first_ases_nm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_chf_reg_2 = progs_chf_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_chf_reg_3 = pd.concat([progs_chf_reg, progs_chf_reg_2], axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = progs_chf_reg.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_chf_reg_3['Admits (1 before 0 after)'] = np.concatenate([np.zeros(n),np.ones(n)],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_chf_reg_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_chf_reg_3['Admits'] = np.where(progs_chf_reg_3['Admits (1 before 0 after)'] == 0, \n",
    "                                    progs_chf_reg_3['adm_90_after'], progs_chf_reg_3['adm_90_before'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_chf_reg_3['Interaction'] = progs_chf_reg_3['chf_ases_yn'] * progs_chf_reg_3['Admits (1 before 0 after)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the filename you wish to save the file to\n",
    "chf_regression_filename = '../data/chf_regression_20190331.csv'\n",
    "\n",
    "# Use this function to search for any files which match your filename\n",
    "files_present = os.path.isfile(chf_regression_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if no matching files, write to csv, if there are matching files, print statement\n",
    "if not files_present:\n",
    "    progs_chf_reg_3.to_csv(chf_regression_filename)\n",
    "else:\n",
    "    print('WARNING: This file already exists!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel Assumption Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_empi_chf = list(progs_chf['EMPI'].unique())\n",
    "rel_admits_chf = admits[admits['EMPI'].isin(rel_empi_chf)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rel_empi_chf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_admits_chf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_admits_chf.iloc[740:780]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_chf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chf_admit_yn, chf_optin_yn, chf_week = tag_chf_admissions(progs_chf, rel_admits_chf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_admits_chf['chf_admit_yn'] = chf_admit_yn\n",
    "rel_admits_chf['chf_optin_yn'] = chf_optin_yn\n",
    "rel_admits_chf['chf_optin_week'] = chf_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_admits_chf_pivot = rel_admits_chf.pivot_table(values='chf_admit_yn', index='chf_optin_week', columns='chf_optin_yn', aggfunc='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the filename you wish to save the file to\n",
    "chf_parallel_filename = '../data/chf_parallel_20190331.csv'\n",
    "\n",
    "# Use this function to search for any files which match your filename\n",
    "files_present = os.path.isfile(chf_parallel_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if no matching files, write to csv, if there are matching files, print statement\n",
    "if not files_present:\n",
    "    rel_admits_chf.pivot_table('chf_admit_yn', index='chf_optin_week', columns='chf_optin_yn', aggfunc='sum').to_csv(chf_parallel_filename)\n",
    "else:\n",
    "    print('WARNING: This file already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_admits_chf_pivot = pd.read_csv(chf_parallel_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figparachf = plt.figure(figsize=(12,10))\n",
    "ax4 = figparachf.add_subplot(111)\n",
    "ax4.plot(rel_admits_chf_pivot['chf_optin_week'], rel_admits_chf_pivot['True'], color='b', label='Opt-ins')\n",
    "ax4.plot(rel_admits_chf_pivot['chf_optin_week'], rel_admits_chf_pivot['False'], color='r', label='Opt-out')\n",
    "#ax1.scatter(X_horses[:,0], X_horses[:,1], color='r', label='horses')\n",
    "ax4.legend(shadow=True, fontsize='x-large')\n",
    "ax4.set_xticks(rel_admits_chf_pivot['chf_optin_week'], minor=True)\n",
    "##ax4.set_xticklabels(rel_admits_chf_pivot['chf_optin_week'], minor=True)\n",
    "##ax1.set_xlabel('Weight (lb)',fontsize=font_size)\n",
    "##ax1.set_ylabel('Height (in)',fontsize=font_size)\n",
    "ax4.set_title('CHF - Parallel Trend',fontsize='xx-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COPD - Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_copd = progs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_copd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_copd = progs_copd[(progs_copd['PRGM_NM']=='DM - CLD') & \n",
    "                      ((progs_copd['prog_create_date']-timedelta(days=90))>progs_copd['Eff_Date']) &\n",
    "                      ((progs_copd['prog_create_date']-timedelta(days=90))<progs_copd['End_Date']) &\n",
    "                        (progs_copd['PRGM_STOP_RSN']!='Auto-Closed')  &\n",
    "                        (progs_copd['prog_create_date']<(datetime.today()-timedelta(days=90)))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify Assessments that occured during COPD window that interfere with the opt-out effect.\n",
    "assess_that_muddy_copd = assess[(assess['ASES_NM'] == 'Social Work Initial') |\n",
    "      ##(assess['ASES_NM'] == 'MCG - DMG - Preventative Assessment') |\n",
    "      ##(assess['ASES_NM'] == 'Social Work Outreach Encounter') |\n",
    "      (assess['ASES_NM'] == 'MCG - DMG - High-Risk Pregnancy - Assessment') | \n",
    "      ##(assess['ASES_NM'] == 'IVR Survey') |\n",
    "      (assess['ASES_NM'] == 'MCG - DMG - Heart Failure') |                         \n",
    "      (assess['ASES_NM']=='MCG - Post-Hospitalization Follow-Up') | \n",
    "      (assess['ASES_NM'] == 'Social Work Note') |\n",
    "      (assess['ASES_NM'] == 'Transplant Notes') |\n",
    "      (assess['ASES_NM'] == 'MCG - DMG - Diabetes, Adult - Knowledge of Condition and Treatment Plan') |\n",
    "      (assess['ASES_NM'] == 'MCG - DMG - Complex Assessment') |\n",
    "      (assess['ASES_NM']=='Post-Hospitalization Follow-up') |\n",
    "      ##(assess['ASES_NM']=='TOC Post Discharge Outreach') | removed on 4/2 per discussion with Sameer and Adam\n",
    "      (assess['ASES_NM']=='CM Medication Reconciliation') |\n",
    "      (assess['ASES_NM']=='Med Reconciliation')].drop_duplicates(subset='PTNT_ASES_DK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create assessments table for COPD\n",
    "\n",
    "assess_copd_mcopdk = assess[assess['ASES_NM']=='MCG - Chronic Obstructive Pulmonary Disease - Knowledge of Condition and Treatment Plan'].drop_duplicates(subset='PTNT_ASES_DK')\n",
    "assess_copd_mdchr = assess[assess['ASES_NM']=='MCG - DMG - Chronic Lung Disease (CLD)'].drop_duplicates(subset='PTNT_ASES_DK')\n",
    "assess_copd_mdcld = assess[assess['ASES_NM']=='MCG - DMG - CLD'].drop_duplicates(subset='PTNT_ASES_DK')\n",
    "frames = [assess_copd_mcopdk, assess_copd_mdchr, assess_copd_mdcld]\n",
    "assess_copd = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_copd_cnt = find_assessments_during_program_dm(progs_copd, assess_that_muddy_copd)\n",
    "progs_copd['assess_dur_copd_cnt'] = assess_copd_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_copd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cnt copd related assessments during programs\n",
    "cnt_copd_90 = find_assessments_during_program_dm(progs_copd, assess_copd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_copd['copd_ases'] = cnt_copd_90\n",
    "cm_copd_ases_yn = list_of_counts_to_flag(cnt_copd_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_copd['copd_ases_yn'] = cm_copd_ases_yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copd_first_ases_dt, copd_first_ases_nm = find_first_assess(progs_copd, assess_copd)\n",
    "\n",
    "progs_copd['copd_first_ases_dt'] = copd_first_ases_dt\n",
    "progs_copd['copd_first_ases_nm'] = copd_first_ases_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copd_interfere_ind = adms_to_one_zero(progs_copd, 'assess_dur_copd_cnt')\n",
    "progs_copd['copd_interfere_ind'] = copd_interfere_ind\n",
    "\n",
    "progs_copd = progs_copd[((progs_copd['copd_interfere_ind']==0) & (progs_copd['copd_ases_yn']==0)) |\n",
    "                     (progs_copd['copd_ases_yn']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_copd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_copd.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the filename you wish to save the file to\n",
    "progs_copd_filename = '../data/progs_copd_20190331.csv'\n",
    "\n",
    "# Use this function to search for any files which match your filename\n",
    "files_present = os.path.isfile(progs_copd_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if no matching files, write to csv, if there are matching files, print statement\n",
    "if not files_present:\n",
    "    progs_copd.to_csv(progs_copd_filename)\n",
    "else:\n",
    "    print('WARNING: This file already exists!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COPD - Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_copd.pivot_table(values=['adm_90_after', 'adm_90_before'], index='copd_ases_yn', aggfunc=['mean', 'count', 'sum'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop Dataset for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_copd_reg = progs_copd.drop(columns = ['index', 'RGON_NM', 'LOB_SUB_CGY', 'ENT_TYPE', 'Eff_Date',\n",
    "       'End_Date', 'PRGM_NM', 'PRGM_STOP_RSN', 'ASGN_USR', 'prog_create_date',\n",
    "       'prog_end_date', 'age', 'is_male', 'index_date', 'lace_score',\n",
    "       'lace_date_prior_enroll', 'lace_to_enroll_days', 'adm_30_after',\n",
    "       'los_30_after', 'los_90_after',\n",
    "       'los_90_before', 'time_to_enroll', 'prog_duration', 'toc_first_ases_dt',\n",
    "       'medrec_first_ases_dt', 'index_to_first_ases', 'index_to_medrec',\n",
    "       'medrec_yn', 'assess_dur_copd_cnt', 'copd_ases',\n",
    "       'copd_interfere_ind', 'copd_first_ases_dt', 'copd_first_ases_nm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_copd_reg_2 = progs_copd_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_copd_reg_3 = pd.concat([progs_copd_reg, progs_copd_reg_2], axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = progs_copd_reg.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_copd_reg_3['Admits (1 before 0 after)'] = np.concatenate([np.zeros(n1),np.ones(n1)],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_copd_reg_3['Admits'] = np.where(progs_copd_reg_3['Admits (1 before 0 after)'] == 0, \n",
    "                                    progs_copd_reg_3['adm_90_after'], progs_copd_reg_3['adm_90_before'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_copd_reg_3['Interaction'] = progs_copd_reg_3['copd_ases_yn'] * progs_copd_reg_3['Admits (1 before 0 after)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the filename you wish to save the file to\n",
    "copd_regression_filename = '../data/copd_regression_20190331.csv'\n",
    "\n",
    "# Use this function to search for any files which match your filename\n",
    "files_present = os.path.isfile(copd_regression_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if no matching files, write to csv, if there are matching files, print statement\n",
    "if not files_present:\n",
    "    progs_copd_reg_3.to_csv(copd_regression_filename)\n",
    "else:\n",
    "    print('WARNING: This file already exists!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel Assumption Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_empi = list(progs_copd['EMPI'].unique())\n",
    "rel_admits = admits[admits['EMPI'].isin(rel_empi)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copd_admit_yn, copd_optin_yn, copd_week = tag_copd_admissions(progs_copd, rel_admits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_admits['copd_admit_yn'] = copd_admit_yn\n",
    "rel_admits['copd_optin_yn'] = copd_optin_yn\n",
    "rel_admits['copd_optin_week'] = copd_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_admits.pivot_table('copd_admit_yn', index='copd_optin_week', columns='copd_optin_yn', aggfunc='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the filename you wish to save the file to\n",
    "copd_parallel_filename = '../data/copd_parallel_20190331.csv'\n",
    "\n",
    "# Use this function to search for any files which match your filename\n",
    "files_present = os.path.isfile(copd_parallel_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if no matching files, write to csv, if there are matching files, print statement\n",
    "if not files_present:\n",
    "    rel_admits.pivot_table('copd_admit_yn', index='copd_optin_week', columns='copd_optin_yn', aggfunc='sum').to_csv(copd_parallel_filename)\n",
    "else:\n",
    "    print('WARNING: This file already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_admits_copd_pivot = pd.read_csv(copd_parallel_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_admits_copd_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figparacopd = plt.figure(figsize=(12,10))\n",
    "ax5 = figparacopd.add_subplot(111)\n",
    "ax5.plot(rel_admits_copd_pivot['copd_optin_week'], rel_admits_copd_pivot['True'], color='b', label='Opt-ins')\n",
    "ax5.plot(rel_admits_copd_pivot['copd_optin_week'], rel_admits_copd_pivot['False'], color='r', label='Opt-out')\n",
    "#ax1.scatter(X_horses[:,0], X_horses[:,1], color='r', label='horses')\n",
    "ax5.legend(shadow=True, fontsize='x-large')\n",
    "ax5.set_xticks(rel_admits_copd_pivot['copd_optin_week'], minor=True)\n",
    "##ax4.set_xticklabels(rel_admits_chf_pivot['chf_optin_week'], minor=True)\n",
    "##ax1.set_xlabel('Weight (lb)',fontsize=font_size)\n",
    "##ax1.set_ylabel('Height (in)',fontsize=font_size)\n",
    "ax5.set_title('COPD - Parallel Trend',fontsize='xx-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
